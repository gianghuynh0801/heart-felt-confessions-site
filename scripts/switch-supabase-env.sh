#!/bin/bash

# Temporary directory and migration file paths
TEMP_DIR="./temp_schema"
MIGRATION_FILE="./migration_backup.sql"

# Function to get schema information interactively
get_schema_info() {
    echo "Enter your schema isolation details:"
    read -p "Project Name [heart]: " PROJECT_NAME
    PROJECT_NAME=${PROJECT_NAME:-"heart"}
    read -p "Schema Name [heart_db]: " SCHEMA_NAME
    SCHEMA_NAME=${SCHEMA_NAME:-"heart_db"}
    read -p "Database User [app_user]: " DB_USER
    DB_USER=${DB_USER:-"app_user"}
    read -p "Production URL (e.g., xyz.supabase.co): " PROD_URL
    read -p "Production API Key: " PROD_KEY
    read -p "Production DB Password (for Session pooler): " PROD_DB_PASSWORD
    read -p "Local URL [https://api.supabase.mbtool.online]: " LOCAL_URL
    LOCAL_URL=${LOCAL_URL:-"https://api.supabase.mbtool.online"}
    read -p "Local API Key [eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoiYW5vbiIsImlhdCI6MTYyMjYxNDgyMiwiZXhwIjoxOTM4MTkwODIyfQ.ZDj4ZPXzyQy6LA7WL5RqWzF1NEg-QmP5ABHrGa_LBQI]: " LOCAL_KEY
    LOCAL_KEY=${LOCAL_KEY:-"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoiYW5vbiIsImlhdCI6MTYyMjYxNDgyMiwiZXhwIjoxOTM4MTkwODIyfQ.ZDj4ZPXzyQy6LA7WL5RqWzF1NEg-QmP5ABHrGa_LBQI"}
    
    # Create temp directory if it doesn't exist
    mkdir -p $TEMP_DIR
    
    # Set schema file path
    SCHEMA_FILE="$TEMP_DIR/${PROJECT_NAME}_schema.sql"
    DATA_FILE="$TEMP_DIR/${PROJECT_NAME}_data.sql"
    RLS_FILE="$TEMP_DIR/${PROJECT_NAME}_rls.sql"
    
    echo "Processing schema migration for:"
    echo "- Project: $PROJECT_NAME"
    echo "- Schema: $SCHEMA_NAME"
    echo "- User: $DB_USER"
}

# Function to update client.ts with schema information
update_client_file() {
    local env=$1
    local target_file="src/integrations/supabase/client.ts"
    
    if [ "$env" = "local" ]; then
        url=$LOCAL_URL
        key=$LOCAL_KEY
        echo "Switching to Local Supabase environment..."
    else
        url=$PROD_URL
        key=$PROD_KEY
        echo "Switching to Production Supabase environment..."
    fi
    
    cat > "$target_file" << EOF
// This file is automatically generated. Do not edit it directly.
import { createClient } from '@supabase/supabase-js';
import type { Database } from './types';

const SUPABASE_URL = "${url}";
const SUPABASE_PUBLISHABLE_KEY = "${key}";
const SCHEMA = "${SCHEMA_NAME}";

// Import the supabase client like this:
// import { supabase } from "@/integrations/supabase/client";

export const supabase = createClient<Database>(
    SUPABASE_URL, 
    SUPABASE_PUBLISHABLE_KEY,
    {
        db: {
            schema: SCHEMA
        }
    }
);
EOF

    echo "Updated $target_file with schema $SCHEMA_NAME"
}

# Check for Supabase CLI
check_supabase_cli() {
    if ! command -v supabase &> /dev/null; then
        echo "Error: Supabase CLI not found"
        echo "Install with: npm install -g supabase"
        exit 1
    fi
}

# Export schema and data from production using Session pooler
export_database() {
    echo "Exporting schema $SCHEMA_NAME from Supabase production..."
    
    # Use Session pooler connection for improved performance
    local POOLER_CONNECTION="postgresql://$DB_USER:$PROD_DB_PASSWORD@$PROD_URL:6543/postgres?search_path=$SCHEMA_NAME"
    
    # Export schema structure
    echo "Exporting schema structure..."
    PGPASSWORD="$PROD_DB_PASSWORD" pg_dump -h $PROD_URL -p 6543 -U $DB_USER -n $SCHEMA_NAME --schema-only --no-owner --no-privileges postgres > "$SCHEMA_FILE"
    
    if [ $? -ne 0 ]; then
        echo "Error: Schema structure export failed"
        exit 1
    fi
    echo "Schema structure exported successfully: $SCHEMA_FILE"
    
    # Export data
    echo "Exporting schema data..."
    PGPASSWORD="$PROD_DB_PASSWORD" pg_dump -h $PROD_URL -p 6543 -U $DB_USER -n $SCHEMA_NAME --data-only --no-owner --no-privileges postgres > "$DATA_FILE"
    
    if [ $? -ne 0 ]; then
        echo "Error: Data export failed"
        exit 1
    fi
    echo "Data exported successfully: $DATA_FILE"

    # Export RLS policies
    echo "Exporting RLS policies..."
    PGPASSWORD="$PROD_DB_PASSWORD" psql -h $PROD_URL -p 6543 -U $DB_USER -d postgres -t -c "
        SELECT 'CREATE POLICY ' || 
               quote_ident(policyname) || ' ON ' || 
               quote_ident(schemaname) || '.' || quote_ident(tablename) || 
               ' AS ' || permissive || 
               ' FOR ' || cmd || 
               ' TO ' || roles || 
               ' USING (' || qual || ')' || 
               CASE WHEN with_check IS NOT NULL THEN ' WITH CHECK (' || with_check || ')' ELSE '' END || ';'
        FROM pg_policies 
        WHERE schemaname = '$SCHEMA_NAME';" > "$RLS_FILE"
    
    if [ $? -ne 0 ]; then
        echo "Error: RLS policies export failed"
        exit 1
    fi
    echo "RLS policies exported successfully: $RLS_FILE"
    
    echo "Database export completed successfully to:"
    echo "- Schema: $SCHEMA_FILE"
    echo "- Data: $DATA_FILE"
    echo "- RLS Policies: $RLS_FILE"
}

# Import schema to local
import_schema() {
    echo "Importing schema $SCHEMA_NAME to local Supabase..."
    
    # Create the schema if it doesn't exist
    psql "postgresql://postgres:postgres@localhost:54321/postgres" -c "CREATE SCHEMA IF NOT EXISTS $SCHEMA_NAME;" 
    
    if [ $? -ne 0 ]; then
        echo "Error: Failed to create schema"
        exit 1
    fi
    
    # Import schema structure
    echo "Importing schema structure..."
    psql "postgresql://postgres:postgres@localhost:54321/postgres" -f "$SCHEMA_FILE"
    
    if [ $? -ne 0 ]; then
        echo "Error: Schema structure import failed"
        exit 1
    fi
    
    # Import data
    echo "Importing data..."
    psql "postgresql://postgres:postgres@localhost:54321/postgres" -f "$DATA_FILE"
    
    if [ $? -ne 0 ]; then
        echo "Error: Data import failed"
        exit 1
    fi
    
    # Import RLS policies
    echo "Importing RLS policies..."
    psql "postgresql://postgres:postgres@localhost:54321/postgres" -f "$RLS_FILE"
    
    if [ $? -ne 0 ]; then
        echo "Error: RLS policies import failed"
        exit 1
    fi

    # Configure user isolation
    echo "Configuring user isolation for $DB_USER on schema $SCHEMA_NAME..."
    psql "postgresql://postgres:postgres@localhost:54321/postgres" << EOF
-- Create the user if it doesn't exist
DO \$\$
BEGIN
    IF NOT EXISTS (SELECT FROM pg_catalog.pg_roles WHERE rolname = '$DB_USER') THEN
        CREATE ROLE $DB_USER WITH LOGIN PASSWORD 'local_password';
    END IF;
END
\$\$;

-- Revoke all permissions first to ensure clean slate
REVOKE ALL PRIVILEGES ON SCHEMA $SCHEMA_NAME FROM PUBLIC, $DB_USER;
REVOKE ALL PRIVILEGES ON ALL TABLES IN SCHEMA $SCHEMA_NAME FROM PUBLIC, $DB_USER;
REVOKE ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA $SCHEMA_NAME FROM PUBLIC, $DB_USER;
REVOKE ALL PRIVILEGES ON ALL FUNCTIONS IN SCHEMA $SCHEMA_NAME FROM PUBLIC, $DB_USER;

-- Grant specific permissions to the user
GRANT USAGE ON SCHEMA $SCHEMA_NAME TO $DB_USER;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA $SCHEMA_NAME TO $DB_USER;
GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA $SCHEMA_NAME TO $DB_USER;
GRANT EXECUTE ON ALL FUNCTIONS IN SCHEMA $SCHEMA_NAME TO $DB_USER;

-- Set default privileges for future objects
ALTER DEFAULT PRIVILEGES IN SCHEMA $SCHEMA_NAME 
GRANT ALL PRIVILEGES ON TABLES TO $DB_USER;

ALTER DEFAULT PRIVILEGES IN SCHEMA $SCHEMA_NAME 
GRANT ALL PRIVILEGES ON SEQUENCES TO $DB_USER;

ALTER DEFAULT PRIVILEGES IN SCHEMA $SCHEMA_NAME 
GRANT EXECUTE ON FUNCTIONS TO $DB_USER;

-- Enable Row Level Security on all tables
DO \$\$
DECLARE
    table_record RECORD;
BEGIN
    FOR table_record IN 
        SELECT tablename 
        FROM pg_tables 
        WHERE schemaname = '$SCHEMA_NAME'
    LOOP
        EXECUTE 'ALTER TABLE $SCHEMA_NAME.' || quote_ident(table_record.tablename) || ' ENABLE ROW LEVEL SECURITY;';
    END LOOP;
END \$\$;
EOF
    
    if [ $? -ne 0 ]; then
        echo "Error: User isolation configuration failed"
        exit 1
    fi
    echo "User isolation configured successfully for $DB_USER on schema $SCHEMA_NAME"
    echo "Import completed successfully!"
}

# Check local Supabase status
check_local_status() {
    echo "Checking local Supabase status..."
    supabase status
    
    if [ $? -ne 0 ]; then
        echo "Starting local Supabase..."
        supabase start
    fi
}

# Show usage instructions
show_usage() {
    echo "Usage: $0 <command>"
    echo "Commands:"
    echo "  export    - Export schema and data from Production using Session pooler"
    echo "  import    - Import schema and data to Local with user isolation"
    echo "  local     - Switch to Local Supabase and configure schema/user isolation"
    echo "  prod      - Switch to Production Supabase"
    echo "  sync      - Full sync (export -> import -> switch to local)"
    exit 1
}

# Main script execution
if [ $# -lt 1 ]; then
    show_usage
fi

COMMAND=$1
get_schema_info

case "$COMMAND" in
    "local"|"prod")
        update_client_file $COMMAND
        ;;
    "export")
        export_database
        ;;
    "import")
        check_supabase_cli
        check_local_status
        import_schema
        ;;
    "sync")
        check_supabase_cli
        check_local_status
        export_database
        import_schema
        update_client_file "local"
        echo "Full sync completed successfully! Your local environment is now set up with data from production."
        ;;
    *)
        show_usage
        ;;
esac

echo "Operation completed successfully!"
